input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
		codec => json_lines {
			target => "[document]"
		}
	}
}

filter {
    if [fields][hostname] =~ /^spic.*$/ {
        grok {
            match => { 
				"message" => "%{TIMESTAMP_ISO8601:timestamp},%{NUMBER:milliseconds} %{LOGLEVEL:loglevel} %{GREEDYDATA:content}" 
			}
			add_field => { 
				"tot_timestamp" => "%{timestamp}.%{milliseconds}"
				"hostname" => "%{[fields][hostname]}" 
				"file_path" => "%{[log][file][path]}"
			}
        }
		grok {
			match => {
				"file_path" => [
					".*/(?<market>[a-z]+)_(?<account>\d+)_(?<type>[a-z]+(_[a-z]+)*).*",
					".*/(?<market>[a-z]+)_(?<type>[a-z]+(_[a-z]+)*).*"
				]
			}
		}
        date {
            match => [ "tot_timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
            target => "timestamp"
        }
		if "_grokparsefailure" in [tags] {
			drop { }
		}
		prune {
            whitelist_names => ["^timestamp$",  "^loglevel$", "^content$", "^hostname$", "^market$", "^account$", "^type$"]
        }
    }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		index => "logstash-%{+YYYY.MM.dd}"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
	}
	stdout {
		codec => rubydebug
	}
}